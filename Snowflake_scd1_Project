-- Establish role and warehouse to be used
USE ROLE ACCOUNTADMIN;
USE WAREHOUSE COMPUTE_WH;

-- Create a database that will create a default PUBLIC schema
CREATE OR REPLACE DATABASE SCD1_DB;

-- Create a storage integration to integrate Snowflake with our s3 bucket in AWS
CREATE OR REPLACE STORAGE INTEGRATION SCD1_INT
    TYPE = EXTERNAL_STAGE
    STORAGE_PROVIDER = 's3'
    ENABLED = TRUE
    STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::505999909011:role/snowflake_scd1_role'
    STORAGE_ALLOWED_LOCATIONS = ('s3://snowflake-scd1-data/data/');

-- Describe the integration to acquire TRUST info to be used by the AWS IAM role
DESC INTEGRATION SCD1_INT;


-- create an external stage in order to be able to access files from s3 bucket
CREATE OR REPLACE STAGE SCD1_DB.PUBLIC.SCD1_STAGE
STORAGE_INTEGRATION = SCD1_INT
URL = 's3://snowflake-scd1-data/data/';

-- test the integration/connection is working
ls @SCD1_DB.PUBLIC.SCD1_STAGE;


-- *****Snowflake Snowpipe Setup*****

USE SCHEMA SCD1_DB.PUBLIC;

-- Create source table to be used to load customer_data into Snowflake
CREATE OR REPLACE TABLE SCD1_DB.PUBLIC.CUSTOMER_SOURCE
(
CUSTOMERNAME string,
PHONE string,
ADDRESSLINE1 string,
ADDRESSLINE2 string,
CITY string,
STATE string,
POSTALCODE string,
COUNTRY string,
TERRITORY string,
CONTACTFIRSTNAME string,
CONTACTLASTNAME string
);

-- Create the pipe
CREATE OR REPLACE PIPE SCD1_DB.PUBLIC.SCD1_PIPE 
AUTO_INGEST = TRUE AS
COPY INTO SCD1_DB.PUBLIC.CUSTOMER_SOURCE
FROM 
(
SELECT
$1 AS CUSTOMERNAME,
$2 AS PHONE,
$3 AS ADDRESSLINE1,
$4 AS ADDRESSLINE2,
$5 AS CITY,
$6 AS STATE,
$7 AS POSTALCODE,
$8 AS COUNTRY,
$9 AS TERRITORY,
$10 AS CONTACTFIRSTNAME,
$11 AS CONTACTLASTNAME

FROM @SCD1_DB.PUBLIC.SCD1_STAGE)

FILE_FORMAT = (TYPE = 'CSV' SKIP_HEADER=1 FIELD_OPTIONALLY_ENCLOSED_BY ='"');

-- check if PIPE is in running status
SELECT SYSTEM$PIPE_STATUS('SCD1_DB.PUBLIC.SCD1_PIPE');

-- Get event notification channel

SHOW PIPES;


-- *****Snowflake Stream Setup*****

-- Create stream
CREATE OR REPLACE STREAM SCD1_DB.PUBLIC.CUSTOMER_STREAM
ON TABLE SCD1_DB.PUBLIC.CUSTOMER_SOURCE
APPEND_ONLY = TRUE; //only adds new records to the customer_source table

-- test that the stream works (was successfully created)
SELECT * FROM SCD1_DB.PUBLIC.CUSTOMER_STREAM;


-- *****Snowflake Task Setup*****
-- create target table, a stored procedure to perform the SCD1 logic on
-- the target table and a task to execute the procedure on a
-- scheduled frequency

-- create target table
CREATE OR REPLACE TABLE SCD1_DB.PUBLIC.CUSTOMER_TARGET
(
CONTACTFIRSTNAME STRING,
CONTACTLASTNAME STRING,
CUSTOMERNAME STRING,
PHONE STRING,
ADDRESSLINE1 STRING,
ADDRESSLINE2 STRING,
CITY STRING,
STATE STRING,
POSTALCODE STRING,
COUNTRY STRING,
TERRITORY STRING,
INSERT_DTS TIMESTAMP(6),
UPDATE_DTS TIMESTAMP(6) -- last 2 columns to help us know when new records are added to the target table
);

-- Create stored procedure (function)
CREATE OR REPLACE PROCEDURE SCD1_DB.PUBLIC.CUSTOMER_SP()
RETURNS VARCHAR(50)
LANGUAGE JAVASCRIPT
EXECUTE AS CALLER

AS

$$
try {

-- Create statement BEGIN, Begins a transaction in the current session
snowflake.execute({sqlText:`BEGIN TRANSACTION;`});

-- load data from Customer Stream to a temp table    

snowflake.execute({sqlText:`CREATE OR REPLACE TEMPORARY TABLE SCD1_DB.PUBLIC.CUSTOMER_TEMP

AS
SELECT
CONTACTFIRSTNAME,
CONTACTLASTNAME,
CUSTOMERNAME,
PHONE,
ADDRESSLINE1,
ADDRESSLINE2,
CITY,
STATE,
POSTALCODE,
COUNTRY,
TERRITORY,
CURRENT_TIMESTAMP(6) AS INSERT_DTS,
CURRENT_TIMESTAMP(6) AS UPDATE_DTS
FROM 
SCD1_DB.PUBLIC.CUSTOMER_STREAM;`});
    
-- Perform the required SCD1 logic on the Customer Target table based on the primary column

snowflake.execute({sqlText:`MERGE INTO SCD1_DB.PUBLIC.CUSTOMER_TARGET TGT

USING SCD1_DB.PUBLIC.CUSTOMER_TEMP TMP
ON TGT.CONTACTFIRSTNAME = TMP.CONTACTFIRSTNAME
AND TGT.CONTACTLASTNAME = TMP.CONTACTLASTNAME

WHEN MATCHED THEN UPDATE SET    
TGT.CUSTOMERNAME = TMP.CUSTOMERNAME,
TGT.PHONE = TMP.PHONE,
TGT.ADDRESSLINE1 = TMP.ADDRESSLINE1,
TGT.ADDRESSLINE2 = TMP.ADDRESSLINE2,
TGT.CITY = TMP.CITY,
TGT.STATE = TMP.STATE,
TGT.POSTALCODE = TMP.POSTALCODE,
TGT.COUNTRY = TMP.COUNTRY,
TGT.TERRITORY = TMP.TERRITORY,
TGT.UPDATE_DTS = TMP.UPDATE_DTS

WHEN NOT MATCHED THEN INSERT 
(
CONTACTFIRSTNAME,
CONTACTLASTNAME,
CUSTOMERNAME,
PHONE,
ADDRESSLINE1,
ADDRESSLINE2,
CITY,
STATE,
POSTALCODE,
COUNTRY,
TERRITORY,
INSERT_DTS,
UPDATE_DTS
)

VALUES 
(
TMP.CONTACTFIRSTNAME,
TMP.CONTACTLASTNAME,
TMP.CUSTOMERNAME,
TMP.PHONE,
TMP.ADDRESSLINE1,
TMP.ADDRESSLINE2,
TMP.CITY,
TMP.STATE,
TMP.POSTALCODE,
TMP.COUNTRY,
TMP.TERRITORY,
TMP.INSERT_DTS,
TMP.UPDATE_DTS
);`});

-- Create statement COMMIT, Commits an open transaction in the current session

snowflake.execute({sqlText:`COMMIT;`});

-- Statement returned for info and debuging purposes

return "Store Procedure Executed Successfully";
}

catch (err)
{
    result = 'Error: ' + err;
    snowflake.execute({sqlText:`ROLLBACK;`});
    throw result;
}

$$;

-- Create a task to execute the above store procedure at a scheduled frequency
-- task is like an ETL job inside Snowflake

-- verify that the store procedure is working
CALL SCD1_DB.PUBLIC.CUSTOMER_SP();

CREATE OR REPLACE TASK SCD1_DB.PUBLIC.CUSTOMER_TASK
WAREHOUSE = COMPUTE_WH
SCHEDULE = '1 MINUTE'
WHEN SYSTEM$STREAM_HAS_DATA('SCD1_DB.PUBLIC.CUSTOMER_STREAM')
AS CALL SCD1_DB.PUBLIC.CUSTOMER_SP(); 

-- Show tasks if running or not - currently it will be in 'suspended' state
SHOW TASKS;

-- Alter task's state to 'resume' - after wh the task will be in 'started' state
ALTER TASK SCD1_DB.PUBLIC.CUSTOMER_TASK RESUME;

-- After loading files to the AWS s3 bucket using the Python code from Anaconda,
-- verify that data has been updated at the source table
SELECT * FROM SCD1_DB.PUBLIC.CUSTOMER_SOURCE;

-- verify that data is on stream
SELECT * FROM SCD1_DB.PUBLIC.CUSTOMER_STREAM;

-- Now check the target table. 
SELECT * FROM SCD1_DB.PUBLIC.CUSTOMER_TARGET;

-- check the phone number of this row
SELECT * FROM SCD1_DB.PUBLIC.CUSTOMER_TARGET
WHERE
CONTACTFIRSTNAME = 'Elizabeth'
AND
CONTACTLASTNAME = 'Yu';

-- check the city of this row
SELECT * FROM SCD1_DB.PUBLIC.CUSTOMER_TARGET
WHERE
CONTACTFIRSTNAME = 'Kyung' 
AND 
CONTACTLASTNAME ='Benitez';

-- check that this row was doesn't exist
SELECT * FROM SCD1_DB.PUBLIC.CUSTOMER_TARGET
WHERE
CONTACTFIRSTNAME = 'John' 
AND 
CONTACTLASTNAME ='Wick';

-- **** Now upload the customer_change_data.csv file into the s3 bucket via the Python script****

-- verify that there has been an update
SELECT * FROM SCD1_DB.PUBLIC.CUSTOMER_TARGET
WHERE
CONTACTFIRSTNAME = 'Elizabeth'
AND
CONTACTLASTNAME = 'Yu';

-- verify that there has been an update
SELECT * FROM SCD1_DB.PUBLIC.CUSTOMER_TARGET
WHERE
CONTACTFIRSTNAME = 'Kyung' 
AND 
CONTACTLASTNAME ='Benitez';

-- verify that this new row was added
SELECT * FROM SCD1_DB.PUBLIC.CUSTOMER_TARGET
WHERE
CONTACTFIRSTNAME = 'John' 
AND 
CONTACTLASTNAME ='Wick';

-- Ensure the task doesn't keep running in the background to reduce cost.
ALTER TASK SCD1_DB.PUBLIC.CUSTOMER_TASK SUSPEND;